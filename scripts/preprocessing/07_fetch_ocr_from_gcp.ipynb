{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read OCR Output from GCP Bucket to Local/DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade google-cloud-videointelligence\n",
    "# pip install --upgrade google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client()\n",
    "bucket_name = 'moj-text-detection-output'\n",
    "bucket = client.get_bucket('moj-text-detection-output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs = client.list_blobs(bucket_name)\n",
    "for b in blobs:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This is the Cloud Function\"\"\"\n",
    "\"\"\"Detect text in a video stored on GCS.\"\"\"\n",
    "import time\n",
    "\n",
    "from google.cloud import videointelligence\n",
    "\n",
    "OUTPUT_BUCKET=\"gs://moj-text-detection-output\"\n",
    "\n",
    "video_client = videointelligence.VideoIntelligenceServiceClient()\n",
    "features = [videointelligence.Feature.TEXT_DETECTION]\n",
    "\n",
    "def detect_text(event, context):\n",
    "  print(event)\n",
    "  input_uri = \"gs://\" + event[\"bucket\"] + \"/\" + event[\"name\"]\n",
    "  file_stem = event[\"name\"].split(\".\")[0]\n",
    "  output_uri = f\"{OUTPUT_BUCKET}/{file_stem} - {time.time()}.json\"\n",
    "\n",
    "  video_client.annotate_video(\n",
    "      request={\n",
    "        \"features\": features, \n",
    "        \"input_uri\": input_uri, \n",
    "        \"output_uri\": output_uri\n",
    "        }\n",
    "  )\n",
    "\n",
    "  print(\"Processing video for text detection. \", input_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"output-moj-video-ocr\"\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "def list_blobs(bucket_name):\n",
    "    \"\"\"Lists all the blobs in the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "\n",
    "    storage_client = storage.Client(project=\"moj-thesis\")\n",
    "\n",
    "    # Note: Client.list_blobs requires at least package version 1.17.0.\n",
    "    blobs = storage_client.list_blobs(bucket_name)\n",
    "\n",
    "    # Note: The call returns a response only when the iterator is consumed.\n",
    "    for blob in blobs:\n",
    "        print(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Lists all the blobs in the bucket.\"\"\"\n",
    "bucket_name = \"input-moj-audios\"\n",
    "\n",
    "storage_client = storage.Client(project=\"moj-thesis\")\n",
    "\n",
    "# Note: Client.list_blobs requires at least package version 1.17.0.\n",
    "blobs = storage_client.list_blobs(bucket_name)\n",
    "\n",
    "# Note: The call returns a response only when the iterator is consumed.\n",
    "# for blob in blobs:\n",
    "#     print(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2r7wN33WrwU5Xd0L7PbbIKZr0eXvNBSp4Bmm.wav\n"
     ]
    }
   ],
   "source": [
    "for blob in blobs:\n",
    "    print(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_BUCKET=\"input-moj-audios\"\n",
    "OUTPUT_BUCKET=\"output-moj-audio\"\n",
    "\n",
    "input_uri = \"2F2r7wN33WrwU5Xd0L7PbbIKZr0eXvNBSp4Bmm.wav\"\n",
    "\n",
    "storage_client = storage.Client(project=\"moj-thesis\")\n",
    "bucket = storage_client.bucket(INPUT_BUCKET)\n",
    "blob = bucket.blob(\"2r7wN33WrwU5Xd0L7PbbIKZr0eXvNBSp4Bmm.wav\")\n",
    "with blob.open(mode=\"rb\") as f:\n",
    "    samplerate, data = wavfile.read(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[         0,          0],\n",
       "       [         0,          0],\n",
       "       [         0,          0],\n",
       "       ...,\n",
       "       [-276627456, -276627456],\n",
       "       [-304873472, -304873472],\n",
       "       [-339935232, -339935232]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_read(bucket_name, blob_name):\n",
    "    \"\"\"Write and read a blob from GCS using file-like IO\"\"\"\n",
    "    # The ID of your GCS bucket\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "\n",
    "    # The ID of your new GCS object\n",
    "    # blob_name = \"storage-object-name\"\n",
    "\n",
    "    storage_client = storage.Client(project=\"moj-thesis\")\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    with blob.open(\"r\", encoding='utf-8') as f:\n",
    "        return (f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(blob_name):\n",
    "    return blob_name.split(\"/\")[-1].split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ocr(blob_name, jsonfile):\n",
    "    text = []\n",
    "    times=[]\n",
    "    if 'text_annotations' not in jsonfile['annotation_results'][0].keys():\n",
    "        return ''\n",
    "    for annotation in jsonfile['annotation_results'][0]['text_annotations']:\n",
    "        if (\"text\" in annotation.keys()):\n",
    "            if (annotation['segments'][0]['confidence'] > 0.9):\n",
    "                \n",
    "                \n",
    "                timechunk = annotation['segments'][0]['segment'][\"start_time_offset\"]\n",
    "                try:\n",
    "\n",
    "                    offset = 0\n",
    "                    if \"seconds\" in timechunk.keys():\n",
    "                        offset += timechunk['seconds']\n",
    "                    if \"nanos\" in timechunk.keys():\n",
    "                        offset += timechunk['nanos'] / 1000000000\n",
    "\n",
    "                    times.append(offset)\n",
    "                    text.append(annotation['text'])\n",
    "                except:\n",
    "                    print(blob_name)\n",
    "                    print('\\t', timechunk)\n",
    "\n",
    "\n",
    "    result = \" \".join([y for (x,y) in sorted(zip(times,text))])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_blobs(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../util/creds.txt\", \"r\") as credsfile:\n",
    "    username = credsfile.readline().strip()\n",
    "    password = credsfile.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client(project=\"moj-thesis\")\n",
    "\n",
    "blobs = storage_client.list_blobs(bucket_name)\n",
    "\n",
    "blob_list = list(blobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host='localhost',\n",
    "    database='moj',\n",
    "    user=username,\n",
    "    password=password\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "insert_count = 0\n",
    "\n",
    "for blob in blob_list:\n",
    "    \n",
    "    blob_name = blob.name\n",
    "\n",
    "    filename = get_file_name(blob_name)\n",
    "    if filename in missing_filenames:\n",
    "        print(filename)\n",
    "        data = write_read(bucket_name, blob_name)\n",
    "        jsonfile = json.loads(data)\n",
    "        result = get_ocr(blob_name, jsonfile)\n",
    "        result = result.replace('\\'', '\\'\\'')\n",
    "\n",
    "        query = (f'insert into \\\"ocr\\\" values (\\'{filename}\\', \\'{result}\\') on conflict do nothing')\n",
    "\n",
    "        cursor.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "        insert_count+=1\n",
    "    \n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(insert_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate + Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../util/creds.txt\", \"r\") as credsfile:\n",
    "    username = credsfile.readline().strip()\n",
    "    password = credsfile.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_url = f'postgresql://{username}:{password}@localhost:5432/moj'\n",
    "\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "dbConnection = engine.connect();\n",
    "\n",
    "query = text('select * from ocr')\n",
    "\n",
    "df = pd.read_sql(query, dbConnection);\n",
    "\n",
    "dbConnection.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eithimalar LITIC JTIC TIC. imalar LIT AL LITRAL CAL Seithimalar'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[81][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from indicnlp import common\n",
    "\n",
    "# The path to the local git repo for Indic NLP library\n",
    "INDIC_NLP_LIB_HOME=r\"C:\\\\Users\\\\archi\\\\capstone\\\\indic_nlp_library\"\n",
    "\n",
    "# The path to the local git repo for Indic NLP Resources\n",
    "INDIC_NLP_RESOURCES=\"C:\\\\Users\\\\archi\\\\capstone\\\\indic_nlp_resources\"\n",
    "\n",
    "# Add library to Python path\n",
    "sys.path.append(r'{}\\src'.format(INDIC_NLP_LIB_HOME))\n",
    "\n",
    "# Set environment variable for resources folder\n",
    "common.set_resources_path(INDIC_NLP_RESOURCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicnlp import loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "from cleantext.sklearn import CleanTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hindiAlphabetRegex():\n",
    "  numberOfHindiCharacters = 128\n",
    "  hindiAlphabet = []\n",
    "  for i in range(numberOfHindiCharacters):\n",
    "    hindiAlphabet.append(\"\\\\u\" + (\"0%0.2X\" % (0x0900 + i)))\n",
    "  alph = \"\".join(hindiAlphabet)\n",
    "  return \"[\" + alph + \"]\"\n",
    "\n",
    "def containsHindiScript(text):\n",
    "    alphabet = hindiAlphabetRegex()\n",
    "    exp = f\".*{alphabet}.*\"\n",
    "    if re.match(exp, text):\n",
    "        return True\n",
    "    return False    # because false can mean it contains punjabi or something\n",
    "\n",
    "# U+0A80..U+0AFF (128 code points)\n",
    "def gujaratiAlphabetRegex():\n",
    "  alphabet = []\n",
    "  for i in range(128):\n",
    "    alphabet.append(\"\\\\u\" + (\"0%0.2X\" % (0x0A80 + i)))\n",
    "  alph = \"\".join(alphabet)\n",
    "  return \"[\" + alph + \"]\"\n",
    "\n",
    "def containsGujaratiScript(text):\n",
    "    alphabet = gujaratiAlphabetRegex()\n",
    "    exp = f\".*{alphabet}.*\"\n",
    "    if re.match(exp, text):\n",
    "        return True\n",
    "    return False    # because false can mean it contains punjabi or something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_caption_lang(df):\n",
    "    df['has_hindi_script'] = df['clean_caption'].apply(containsHindiScript)\n",
    "    df['has_gujarati_script'] = df['clean_caption'].apply(containsGujaratiScript)\n",
    "    df['is_english'] = df['clean_caption'].apply(lambda x: x.isascii())\n",
    "    df['is_empty'] = df['clean_caption'].str.match(r\"^$\")\n",
    "\n",
    "    conditions = [\n",
    "        (df['is_empty'] == True),\n",
    "        (df['is_english'] == True),\n",
    "        (df['has_hindi_script'] == True),\n",
    "        (df['has_gujarati_script'] == True),\n",
    "        (df['has_gujarati_script'] == False) & (df['has_hindi_script'] == False) & (df['is_english'] == False),  \n",
    "    ]\n",
    "\n",
    "    values = ['empty', 'en', 'hi', 'gj', 'other']\n",
    "\n",
    "    df['caption_lang'] = np.select(conditions, values)\n",
    "\n",
    "    df.drop(columns=['has_hindi_script', 'has_gujarati_script', 'is_english', 'is_empty'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_14720\\3011050540.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  cleaned_without_mentions = combined.text.str.replace(exp_remove_mentions, \"\")\n",
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_14720\\3011050540.py:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  cleaned_without_hashtags = cleaned_without_mentions.str.replace(exp_remove_hashtags, \"\")\n",
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_14720\\3011050540.py:23: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  combined.clean_caption = combined.clean_caption.str.replace(punct, '')\n",
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_14720\\3011050540.py:24: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  combined.clean_caption = combined.clean_caption.str.replace(\"\\s+\", ' ')     # normalize white space\n"
     ]
    }
   ],
   "source": [
    "# Clean characters, etc from captions\n",
    "combined = df\n",
    "\n",
    "cleaner = CleanTransformer(no_punct = True, \n",
    "                           lower=True, \n",
    "                           no_emoji=True, \n",
    "                           no_line_breaks=True, \n",
    "                           no_urls=True, \n",
    "                           normalize_whitespace=True,\n",
    "                           to_ascii=False)\n",
    "\n",
    "exp_remove_hashtags = \"#+[^\\s]+\"\n",
    "exp_remove_mentions = \"@+[^\\s]+\"\n",
    "\n",
    "cleaned_without_mentions = combined.text.str.replace(exp_remove_mentions, \"\")\n",
    "cleaned_without_hashtags = cleaned_without_mentions.str.replace(exp_remove_hashtags, \"\")\n",
    "cleaned_final = cleaner.transform(cleaned_without_hashtags)\n",
    "combined['clean_caption'] = cleaned_final\n",
    "\n",
    "punct_to_remove = ['$', '+', '<', '=', '>', '^', '`', '|', '~']\n",
    "# extra cleaning. because these characters were missed for some reason\n",
    "for punct in punct_to_remove:\n",
    "    combined.clean_caption = combined.clean_caption.str.replace(punct, '')\n",
    "combined.clean_caption = combined.clean_caption.str.replace(\"\\s+\", ' ')     # normalize white space\n",
    "combined.clean_caption = combined.clean_caption.str.strip()\n",
    "combined.reset_index(inplace=True)\n",
    "\n",
    "get_caption_lang(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicnlp.transliterate.unicode_transliterate import ItransTransliterator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_captions():\n",
    "    sample_captions = combined['clean_caption'].sample(50)\n",
    "    non_empty_captions = sample_captions[(sample_captions.str.match(r\"^$\") == False) & (sample_captions.apply(isEnglish))]\n",
    "    print(len(non_empty_captions), \" captions\")\n",
    "    return non_empty_captions\n",
    "\n",
    "def write_to_LID(captions, filename = \"captions.txt\"):\n",
    "    # now lets write these to a txt file in the necessary format\n",
    "    \n",
    "    with open(f\"C:\\\\Users\\\\archi\\\\capstone\\\\LID-tool\\\\{filename}\", \"w\") as outfile:\n",
    "        for i,caption in enumerate(captions):\n",
    "            outfile.write(f\"{i}\\t{caption}\\n\")\n",
    "\n",
    "# go to command prompt \\LID-tools and run python getLanguage.py captions.txt\n",
    "\n",
    "def read_LID_results(filename = \"captions.txt_tagged\"):\n",
    "    # run python script in the cmd bc issues with jupyter \n",
    "    with open(f\"C:\\\\Users\\\\archi\\\\capstone\\\\LID-tool\\\\{filename}\", \"r\") as datafile:\n",
    "        lines = datafile.readlines()\n",
    "\n",
    "    lid_res = lines[1::2]  # classified captions\n",
    "\n",
    "    lid_words = list() \n",
    "    for caption in lid_res:\n",
    "        words = caption.split()[1:]\n",
    "        word_groups = list()\n",
    "        for word in words:\n",
    "            word_groups.append(word.split(\"/\"))\n",
    "        lid_words.append(word_groups)\n",
    "    # better way would be to separate all words of all cleaned captions and then add the classifications\n",
    "\n",
    "    return lid_words\n",
    "\n",
    "def transliterateCaption(classified_caption):\n",
    "    # writing a function that does all the work in one go so i can test how it works on diff sampled captions\n",
    "\n",
    "    # classified_caption is like [ [word, HI] ...]\n",
    "    # get the longest substring\n",
    "    # classified_caption = []\n",
    "    \n",
    "    lang = 1\n",
    "\n",
    "    max_hindi_lens = [ 1 if classified_caption[0][lang] == 'HI' else 0]\n",
    "\n",
    "    for i, word in enumerate(classified_caption):\n",
    "        if i == 0: \n",
    "            continue\n",
    "        if word[lang] == 'HI':\n",
    "            max_hindi_lens.append(max_hindi_lens[i-1]+1)\n",
    "        else:\n",
    "            max_hindi_lens.append(0)\n",
    "\n",
    "    np_max_hindi_lens = np.array(max_hindi_lens)\n",
    "\n",
    "    if np_max_hindi_lens.max() > 0:\n",
    "        end_of_str = np_max_hindi_lens.argmax()\n",
    "        start_of_str = end_of_str - max_hindi_lens[end_of_str] + 1\n",
    "        all_words = [ word[0] for word in classified_caption[start_of_str:end_of_str+1]]\n",
    "        final_str = \" \".join(all_words)\n",
    "\n",
    "        print(final_str)\n",
    "\n",
    "        caption_to_script = ItransTransliterator.from_itrans(final_str, 'hi')\n",
    "        print(\"Option 1\")\n",
    "        print(caption_to_script)\n",
    "    else:\n",
    "        print(\"All english\")\n",
    "\n",
    "    # second option is to individually translate each word and put the script together\n",
    "\n",
    "    caption_words_2 = list()\n",
    "    for classified_word in classified_caption:\n",
    "        if classified_word[lang] == 'HI':\n",
    "            word_script = ItransTransliterator.from_itrans(classified_word[0], 'hi')\n",
    "            caption_words_2.append(word_script)\n",
    "        else:\n",
    "            caption_words_2.append(classified_word[0])\n",
    "    caption_to_script_2 = \" \".join(caption_words_2)\n",
    "\n",
    "    print(\"Option 2\")\n",
    "    print(caption_to_script_2)\n",
    "\n",
    "def create_roman_hindi_list(classified_captions):\n",
    "    all_words = list()\n",
    "\n",
    "    word_index = 0\n",
    "    lang_index = 1\n",
    "\n",
    "    for caption in classified_captions:\n",
    "        for word_group in caption:\n",
    "            if word_group[lang_index] == 'HI':\n",
    "                all_words.append(word_group[word_index])\n",
    "\n",
    "    roman_hindi_list = pd.Series(all_words).unique()\n",
    "\n",
    "    print(f\"{len(roman_hindi_list)}/{len(all_words)} unique\")\n",
    "\n",
    "    return roman_hindi_list\n",
    "\n",
    "def transliterate_word(x):\n",
    "    return ItransTransliterator.from_itrans(x, 'hi')\n",
    "\n",
    "# Imports the Google Cloud Translation library\n",
    "from google.cloud import translate\n",
    "\n",
    "# Initialize Translation client\n",
    "def detect_language(text=\"सर्कार\"):\n",
    "\n",
    "    try:\n",
    "               \n",
    "        project_id=\"moj-thesis\"\n",
    "        client = translate.TranslationServiceClient()\n",
    "\n",
    "        location = \"global\"\n",
    "\n",
    "        parent = f\"projects/{project_id}/locations/{location}\"\n",
    "\n",
    "        response = client.detect_language(parent=f\"projects/{project_id}/locations/global\", \n",
    "                                          content=text)\n",
    "       \n",
    "\n",
    "        # Display the translation for each input text provided\n",
    "        for language in response.languages:\n",
    "            return language.language_code\n",
    "        \n",
    "    except:\n",
    "        return \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud Translation library\n",
    "from google.cloud import translate\n",
    "\n",
    "# Initialize Translation client\n",
    "def translate_text(text=\"सर्कार\", lang=\"hi\"):\n",
    "\n",
    "    try:\n",
    "        if lang == 'en':\n",
    "            return ''\n",
    "\n",
    "        \n",
    "        project_id=\"moj-thesis\"\n",
    "        client = translate.TranslationServiceClient()\n",
    "\n",
    "        location = \"global\"\n",
    "\n",
    "        parent = f\"projects/{project_id}/locations/{location}\"\n",
    "\n",
    "        response = client.translate_text(\n",
    "            request={\n",
    "                \"parent\": parent,\n",
    "                \"contents\": [text],\n",
    "                \"mime_type\": \"text/plain\",  # mime types: text/plain, text/html\n",
    "                \"source_language_code\": lang,\n",
    "                \"target_language_code\": \"en-US\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Display the translation for each input text provided\n",
    "        for translation in response.translations:\n",
    "            return translation.translated_text\n",
    "    except:\n",
    "        return \"error\"\n",
    "# translate_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_14720\\553591566.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  english_captions.drop(captions_to_exclude, inplace=True)    # I will leave the 4 captions as is\n"
     ]
    }
   ],
   "source": [
    "english_captions = combined[combined.caption_lang == 'en']\n",
    "len_captions = english_captions.clean_caption.apply(lambda x: len(x.split()))\n",
    "captions_to_exclude = len_captions.nlargest(20).index   # these have about 300 words or more - LID-tool freezes\n",
    "english_captions.drop(captions_to_exclude, inplace=True)    # I will leave the 4 captions as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_captions = combined[combined.caption_lang == 'en']\n",
    "english_captions.to_csv(\"translations/captions_too_long.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_20676\\3300663667.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  english_captions.drop(captions_to_exclude, inplace=True)    # I will leave the 4 captions as is\n",
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_20676\\3300663667.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  english_captions.drop(index=236, inplace=True)    # Keeps hanging on \"farjina\"\n",
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_20676\\3300663667.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  english_captions.drop(index=503, inplace=True)    # Keeps hanging on \"bhaktivedanta\"\n",
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_20676\\3300663667.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  english_captions.drop(index=551, inplace=True)    # Keeps hanging on \"witha\"\n",
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_20676\\3300663667.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  english_captions.drop(index=762, inplace=True)    # Keeps hanging on \"witha\"\n",
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_20676\\3300663667.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  english_captions.drop(index=1235, inplace=True)    # Keeps hanging on \"jarurat\"\n",
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_20676\\3300663667.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  english_captions.drop(index=1443, inplace=True)    # Keeps hanging on \"modi mot\"\n",
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_20676\\3300663667.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  english_captions.drop(index=1747, inplace=True)    # Keeps hanging on \"modi mot\"\n",
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_20676\\3300663667.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  english_captions.drop(index=2592, inplace=True)    # Keeps hanging on \"inspi sinpire mot\"\n",
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_20676\\3300663667.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  english_captions.drop(index=2594, inplace=True)    # Keeps hanging on \"inspi sinpire mot\"\n",
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_20676\\3300663667.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  english_captions.drop(index=2669, inplace=True)    # Keeps hanging on \"inspi sinpire mot\"\n",
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_20676\\3300663667.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  english_captions.drop(index=2725, inplace=True)    # Keeps hanging on \"inspi sinpire mot\"\n",
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_20676\\3300663667.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  english_captions.drop(index=2838, inplace=True)    # Keeps hanging on \"inspi sinpire mot\"\n",
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_20676\\3300663667.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  english_captions.drop(index=2907, inplace=True)    # Keeps hanging on \"inspi sinpire mot\"\n"
     ]
    }
   ],
   "source": [
    "# Identify English/roman Hindi captions\n",
    "english_captions = combined[combined.caption_lang == 'en']\n",
    "len_captions = english_captions.clean_caption.apply(lambda x: len(x.split()))\n",
    "captions_to_exclude = len_captions.nlargest(13).index   # these have about 300 words or more - LID-tool freezes\n",
    "english_captions.drop(captions_to_exclude, inplace=True)    # I will leave the 4 captions as is\n",
    "english_captions.drop(index=236, inplace=True)    # Keeps hanging on \"farjina\"\n",
    "english_captions.drop(index=503, inplace=True)    # Keeps hanging on \"bhaktivedanta\"\n",
    "english_captions.drop(index=551, inplace=True)    # Keeps hanging on \"witha\"\n",
    "english_captions.drop(index=762, inplace=True)    # Keeps hanging on \"witha\"\n",
    "english_captions.drop(index=1235, inplace=True)    # Keeps hanging on \"jarurat\"\n",
    "english_captions.drop(index=1443, inplace=True)    # Keeps hanging on \"modi mot\"\n",
    "english_captions.drop(index=1747, inplace=True)    # Keeps hanging on \"modi mot\"\n",
    "english_captions.drop(index=2592, inplace=True)    # Keeps hanging on \"inspi sinpire mot\"\n",
    "english_captions.drop(index=2594, inplace=True)    # Keeps hanging on \"inspi sinpire mot\"\n",
    "english_captions.drop(index=2669, inplace=True)    # Keeps hanging on \"inspi sinpire mot\"\n",
    "english_captions.drop(index=2725, inplace=True)    # Keeps hanging on \"inspi sinpire mot\"\n",
    "english_captions.drop(index=2838, inplace=True)    # Keeps hanging on \"inspi sinpire mot\"\n",
    "english_captions.drop(index=2907, inplace=True)    # Keeps hanging on \"inspi sinpire mot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: clean_caption, dtype: object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_captions[english_captions.clean_caption.str.contains(\"prahar karega\")].clean_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_captions.loc[2907                ].clean_caption.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocr_round2_0_6.txt\n"
     ]
    }
   ],
   "source": [
    "# Run LID in groups of 100 to separate roman Hindi and English words in the english captions\n",
    "\n",
    "lid_final_files = list()\n",
    "\n",
    "i = 0\n",
    "while i < len(english_captions):\n",
    "    start = i\n",
    "    end = i + 50\n",
    "    if end > len(english_captions):\n",
    "        end = len(english_captions)\n",
    "\n",
    "    filename = f\"ocr_round2_{start}_{end}.txt\"\n",
    "    lid_final_files.append(filename)\n",
    "    print(filename)\n",
    "    \n",
    "    captions = english_captions.iloc[start:end].clean_caption\n",
    "    write_to_LID(captions, filename=filename)\n",
    "\n",
    "    i = end\n",
    "    \n",
    "    # cd capstone\\LID-tool\n",
    "    # set MALLET_HOME=C:\\Users\\archi\\capstone\\LID-tool\\mallet-2.0.8\\\n",
    "    # python getLanguage.py captions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"51\tkaran edit karan eds karan edis karay dis karap edits karan edits karan euits katon edits karan edits 4 kanan edits wami prabhupada his divine orace a c bhaktivedanta swami prabhupada his divine grace a cbhaktivedanta swami frabhupada his divine grace ac bhaktivedanta swami prabhupada his divine orace a c bhaktivedanta swami prabhupada bhagavad his divine orace ac cbhaktivedanta swami prabhupada his divine orace a cbhaktivedanta swami prabhupada his divine orace ac bhaktivedanta swami prabhupada his divine grace a c bhaktivedanta swami prabhupada karan edifs h is divine grace a bhaktivedanta swami prabhupada his divine grace a c bhaktivedanta swami prabhupada edits s divine orace a c bi aran edits divine orace a c bhaktivedanta swami prabhupada divine orace a c bhaktivedanta swami prabhupada divine orace a c bhaktivedanta swami prabhupada divine orace a c bhaktivedanta swami pradhupada divine grace a c bhaktivedanta swami praibhupada pivine grace a c bhaktivedanta swami pradhupada hagavad ivine orace a c bhaktivedanta swami prabhupada vine orace a c bhaktivedanta swami prabhupada vine grace a c bhaktivedanta swami prabhupada\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = list()\n",
    "\n",
    "word_index = 0\n",
    "lang_index = 1\n",
    "\n",
    "for caption in classified_captions:\n",
    "    for word_group in caption:\n",
    "        \n",
    "        try:\n",
    "            if word_group[lang_index] == 'HI':\n",
    "                all_words.append(word_group[word_index])\n",
    "        except:\n",
    "            print(word_group)\n",
    "\n",
    "roman_hindi_list = pd.Series(all_words).unique()\n",
    "\n",
    "print(f\"{len(roman_hindi_list)}/{len(all_words)} unique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocr_round2_0_8.txt\n",
      "40/72 unique\n"
     ]
    }
   ],
   "source": [
    "# Collect all the Roman hindi words identified\n",
    "all_roman_hindi_words = list()\n",
    "for filename in lid_final_files:\n",
    "    print(filename)\n",
    "    classified_captions = read_LID_results(filename=f\"{filename}_tagged\")\n",
    "    roman_hindi_list = create_roman_hindi_list(classified_captions)\n",
    "    all_roman_hindi_words.append(roman_hindi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transliterate and translate all Roman hindi words\n",
    "final_rh_words = np.unique(np.concatenate(all_roman_hindi_words))\n",
    "len(final_rh_words)\n",
    "roman_hindi_translations = pd.DataFrame({\"word\": final_rh_words})\n",
    "roman_hindi_translations['hindi_word'] = roman_hindi_translations.word.apply(transliterate_word)\n",
    "roman_hindi_translations[\"translation\"] = roman_hindi_translations.hindi_word.apply(translate_text)\n",
    "# roman_hindi_translations.to_csv(\"translations/roman_hindi_ocr_round2_final.csv\")\n",
    "roman_hindi_translations.to_csv(\"translations/roman_hindi_ocr_round3_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en', 'gj'], dtype=object)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.caption_lang.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate all Hindi captions\n",
    "hindi_captions = combined[combined.caption_lang == 'hi']\n",
    "hindi_translation = hindi_captions.clean_caption.apply(translate_text)\n",
    "final_hindi_translations = pd.DataFrame({\"filename\": hindi_captions[\"filename\"], \n",
    "                                         \"clean_caption\": hindi_captions['clean_caption'], \n",
    "                                         \"hi_translated_caption\": hindi_translation})\n",
    "# final_hindi_translations.to_csv(\"translations/hindi_ocr_round2_final.csv\")\n",
    "# final_hindi_translations.to_csv(\"translations/hindi_ocr_round3_final.csv\")\n",
    "final_hindi_translations.to_csv(\"translations/hindi_ocr_round4_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_14720\\4107317969.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  other_captions[\"google_lang\"] = other_captions.clean_caption.apply(detect_language)\n"
     ]
    }
   ],
   "source": [
    "# Translate all other language captions\n",
    "other_captions = combined[combined.caption_lang == 'gj']\n",
    "len(other_captions)\n",
    "other_captions[\"google_lang\"] = other_captions.clean_caption.apply(detect_language)\n",
    "# to avoid the slicing issues\n",
    "other_captions_df = pd.DataFrame({\n",
    "    \"filename\": other_captions.filename,\n",
    "    \"caption\": other_captions.clean_caption, \n",
    "    \"caption_lang\": other_captions.caption_lang, \n",
    "    \"google_lang\": other_captions.google_lang, \n",
    "    \"translation\": \"\", # this is what we'll fill in\n",
    "})\n",
    "\n",
    "for i in other_captions_df.index:\n",
    "    row = other_captions_df.loc[i]\n",
    "    other_captions_df.loc[i, \"translation\"] = translate_text(row.caption, row.google_lang)     # to avoid slice setting error use .loc[i, \"\"]\n",
    "# other_captions_df.to_csv(\"translations/other_ocr_round2_final.csv\")\n",
    "other_captions_df.to_csv(\"translations/other_ocr_round4_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>filename</th>\n",
       "      <th>caption</th>\n",
       "      <th>caption_lang</th>\n",
       "      <th>google_lang</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>4rAQ0LLGrQUKdw6yVXpphPlZYjZdD8sNkj4A</td>\n",
       "      <td>આદમી આમ આદ</td>\n",
       "      <td>gj</td>\n",
       "      <td>gu</td>\n",
       "      <td>Adami etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>PnL2655ln2sEvKxmDZjjTWb8EV858rFQPlb6</td>\n",
       "      <td>jaybhagwan13 gjaybhagwan13 gjaybhagwan13 મોગલધ...</td>\n",
       "      <td>gj</td>\n",
       "      <td>gu</td>\n",
       "      <td>jaybhagwan13 gjaybhagwan13 gjaybhagwan13 mogul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>vP4j5223PjTGjVkr9pBBuELB22K3KnfX6VVP</td>\n",
       "      <td>mat karo kisi ke liye itna ki usko aapki kadar...</td>\n",
       "      <td>gj</td>\n",
       "      <td>gu</td>\n",
       "      <td>mat karo kisi ke liye itna ki usko aapki kadar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>VN7YD553NYHmJ1Qn3xooseZgm39r5mUkgX6R</td>\n",
       "      <td>ઘુસાડી દિધુ ભીમસિંહ હોસ્પિટલમાં વકીલ પોતાના રા...</td>\n",
       "      <td>gj</td>\n",
       "      <td>gu</td>\n",
       "      <td>At Ghusadi Didhu Bhimsingh Hospital, a lawyer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>Zm0ZD559mZCjx85k06XXFXyOj4Xd7psdxgXy</td>\n",
       "      <td>પાણીમાં રાજસ્થાન રાજસ્થાનમાં પાણી કે</td>\n",
       "      <td>gj</td>\n",
       "      <td>gu</td>\n",
       "      <td>Water in Rajasthan Water in Rajasthan K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>mPRdKmmXPdTZlxY4GekkTyYOenLB5JIlggmr</td>\n",
       "      <td>અષાઢી બીજ ની રામદેપીર ની આરતી તોરણીયા 2062023 ...</td>\n",
       "      <td>gj</td>\n",
       "      <td>gu</td>\n",
       "      <td>Ashadhi Bija's Ramdepir's Aarti Tornia 2062023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23</td>\n",
       "      <td>oPvXdwwyPXT1rP6o0DjjTwZylGynxecljP8E</td>\n",
       "      <td>ગોંડલ ચોકડી પાસે 2 માલ વાહક ગાડી નહી નો થયો અક...</td>\n",
       "      <td>gj</td>\n",
       "      <td>gu</td>\n",
       "      <td>2 goods carrier near Gondal chowkdi no acciden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24</td>\n",
       "      <td>3rmOYVVvrOUNAoByj9WWSZej6Vj7mvU5XpZN</td>\n",
       "      <td>૭૨ વર્ષ પછી ભગવાન જગન્નાથ નવા રથ ઉપર razyamdav...</td>\n",
       "      <td>gj</td>\n",
       "      <td>gu</td>\n",
       "      <td>After 72 years Lord Jagannath on new chariot r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25</td>\n",
       "      <td>7PjR5NNVPRT5D6dQRmOOIkL48X8AjVSpPKx2</td>\n",
       "      <td>rajasadhi 004 rajasadhi004 આ બધો ઠાઠ ઠાઠનો એનો...</td>\n",
       "      <td>gj</td>\n",
       "      <td>gu</td>\n",
       "      <td>rajasadhi 004 rajasadhi004 all this is his, al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35</td>\n",
       "      <td>xPYr5BBLPrTOx6PADjeeuXd1EV1v12i3pLlA</td>\n",
       "      <td>jaybhagwan13 gjaybhagwan13 ઉjaybhagwan13 jaybh...</td>\n",
       "      <td>gj</td>\n",
       "      <td>gu</td>\n",
       "      <td>jaybhagwan13 gjaybhagwan13 ujaybhagwan13 jaybh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36</td>\n",
       "      <td>11QA4nnK1AHERwnV6AyyTblkRkNXP2FNdnKn</td>\n",
       "      <td>jignesh barot sagardan gkapadiya piyush4 gkapa...</td>\n",
       "      <td>gj</td>\n",
       "      <td>hi</td>\n",
       "      <td>jignesh barot sagardan gkapadiya piyush4 gkapa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                              filename  \\\n",
       "0           10  4rAQ0LLGrQUKdw6yVXpphPlZYjZdD8sNkj4A   \n",
       "1           12  PnL2655ln2sEvKxmDZjjTWb8EV858rFQPlb6   \n",
       "2           18  vP4j5223PjTGjVkr9pBBuELB22K3KnfX6VVP   \n",
       "3           20  VN7YD553NYHmJ1Qn3xooseZgm39r5mUkgX6R   \n",
       "4           21  Zm0ZD559mZCjx85k06XXFXyOj4Xd7psdxgXy   \n",
       "5           22  mPRdKmmXPdTZlxY4GekkTyYOenLB5JIlggmr   \n",
       "6           23  oPvXdwwyPXT1rP6o0DjjTwZylGynxecljP8E   \n",
       "7           24  3rmOYVVvrOUNAoByj9WWSZej6Vj7mvU5XpZN   \n",
       "8           25  7PjR5NNVPRT5D6dQRmOOIkL48X8AjVSpPKx2   \n",
       "9           35  xPYr5BBLPrTOx6PADjeeuXd1EV1v12i3pLlA   \n",
       "10          36  11QA4nnK1AHERwnV6AyyTblkRkNXP2FNdnKn   \n",
       "\n",
       "                                              caption caption_lang  \\\n",
       "0                                          આદમી આમ આદ           gj   \n",
       "1   jaybhagwan13 gjaybhagwan13 gjaybhagwan13 મોગલધ...           gj   \n",
       "2   mat karo kisi ke liye itna ki usko aapki kadar...           gj   \n",
       "3   ઘુસાડી દિધુ ભીમસિંહ હોસ્પિટલમાં વકીલ પોતાના રા...           gj   \n",
       "4                પાણીમાં રાજસ્થાન રાજસ્થાનમાં પાણી કે           gj   \n",
       "5   અષાઢી બીજ ની રામદેપીર ની આરતી તોરણીયા 2062023 ...           gj   \n",
       "6   ગોંડલ ચોકડી પાસે 2 માલ વાહક ગાડી નહી નો થયો અક...           gj   \n",
       "7   ૭૨ વર્ષ પછી ભગવાન જગન્નાથ નવા રથ ઉપર razyamdav...           gj   \n",
       "8   rajasadhi 004 rajasadhi004 આ બધો ઠાઠ ઠાઠનો એનો...           gj   \n",
       "9   jaybhagwan13 gjaybhagwan13 ઉjaybhagwan13 jaybh...           gj   \n",
       "10  jignesh barot sagardan gkapadiya piyush4 gkapa...           gj   \n",
       "\n",
       "   google_lang                                        translation  \n",
       "0           gu                                          Adami etc  \n",
       "1           gu  jaybhagwan13 gjaybhagwan13 gjaybhagwan13 mogul...  \n",
       "2           gu  mat karo kisi ke liye itna ki usko aapki kadar...  \n",
       "3           gu  At Ghusadi Didhu Bhimsingh Hospital, a lawyer,...  \n",
       "4           gu            Water in Rajasthan Water in Rajasthan K  \n",
       "5           gu  Ashadhi Bija's Ramdepir's Aarti Tornia 2062023...  \n",
       "6           gu  2 goods carrier near Gondal chowkdi no acciden...  \n",
       "7           gu  After 72 years Lord Jagannath on new chariot r...  \n",
       "8           gu  rajasadhi 004 rajasadhi004 all this is his, al...  \n",
       "9           gu  jaybhagwan13 gjaybhagwan13 ujaybhagwan13 jaybh...  \n",
       "10          hi  jignesh barot sagardan gkapadiya piyush4 gkapa...  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_captions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean any false RH translations (using work from thesis)\n",
    "prev_rh = pd.read_csv(\"../clean/captions/reviewed/roman_hindi_final.csv\")\n",
    "# rh_words_df = pd.read_csv(\"translations/roman_hindi_ocr_round2_final.csv\")\n",
    "rh_words_df = pd.read_csv(\"translations/roman_hindi_ocr_round3_final.csv\")\n",
    "# rh_words_df = pd.read_csv(\"translations/roman_hindi_ocr_round2_final.csv\")\n",
    "rh_merged = rh_words_df.merge(prev_rh, how='left', left_on=\"word\", right_on=\"word\").drop(columns=[\"Unnamed: 0_y\", \"hindi_word_y\", \"translation_y\"])\n",
    "rh_merged.columns=[\"Unnamed: 0\", \"word\", \"hindi_word\", \"translation\", \"translation_reviewed\"]\n",
    "rh_merged['translation_reviewed'] = np.where(rh_merged['translation_reviewed'].isna(), rh_merged['translation'], rh_merged['translation_reviewed'])\n",
    "rh_words_df = rh_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_14720\\2693744541.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined['translation'] = \"\"    # blank to fill in\n"
     ]
    }
   ],
   "source": [
    "# Combine them all\n",
    "combined['translation'] = \"\"    # blank to fill in\n",
    "# hindi_final_df = pd.read_csv(\"translations/hindi_ocr_round2_final.csv\").rename(columns={\"Unnamed: 0\": \"combined_index\"})\n",
    "# other_final_df = pd.read_csv(\"translations/other_ocr_round2_final.csv\").rename(columns={\"Unnamed: 0\": \"combined_index\"})\n",
    "hindi_final_df = pd.read_csv(\"translations/hindi_ocr_round3_final.csv\").rename(columns={\"Unnamed: 0\": \"combined_index\"})\n",
    "other_final_df = pd.read_csv(\"translations/other_ocr_round3_final.csv\").rename(columns={\"Unnamed: 0\": \"combined_index\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hindi_final_df = hindi_final_df.merge(combined[[\"clean_caption\", \"filename\"]], on=\"clean_caption\")\n",
    "# other_final_df = other_final_df.merge(combined[[\"clean_caption\", \"filename\"]], left_on=\"caption\", right_on=\"clean_caption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_final_df[\"caption_lang\"] = \"hi\"\n",
    "hindi_final_df[\"translation\"] = hindi_final_df[\"hi_translated_caption\"]\n",
    "hindi_final_df = hindi_final_df[[\"filename\", \"caption_lang\", \"clean_caption\", \"translation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'filename', 'caption', 'caption_lang', 'google_lang',\n",
       "       'translation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_final_df = pd.read_csv(\"translations/other_ocr_round4_final.csv\")\n",
    "other_final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'filename', 'caption', 'caption_lang', 'google_lang',\n",
       "       'translation', 'clean_caption'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_final_df[\"clean_caption\"] = other_final_df[\"caption\"]\n",
    "other_final_df[\"caption_lang\"] = other_final_df[\"google_lang\"]\n",
    "other_final_df = other_final_df[[\"filename\", \"caption_lang\", \"clean_caption\", \"translation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_final_df.to_csv(\"translations/ocr_final_round4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_final_df = combined[combined.caption_lang == \"empty\"][[\"filename\", \"caption_lang\", \"clean_caption\"]]\n",
    "empty_final_df[\"translation\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_14720\\654082089.py:14: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  final_res['translation_reviewed'] = final_res.translation_reviewed.str.lower().str.strip(string_punct).str.replace(\".\", \"\")\n"
     ]
    }
   ],
   "source": [
    "# combined the Roman hindi and english word translations\n",
    "eng_cap_exploded = english_captions.clean_caption.str.split().explode().reset_index().rename(columns={\"clean_caption\":\"word\"})\n",
    "\n",
    "joined = eng_cap_exploded.merge(rh_words_df, how=\"outer\", on=\"word\")\n",
    "joined['translation_reviewed'] = np.where(\n",
    "    joined['translation_reviewed'].isna(), \n",
    "    joined['word'], \n",
    "    joined['translation_reviewed'])\n",
    "\n",
    "joined.dropna(subset=[\"index\"], inplace=True)\n",
    "\n",
    "string_punct = '.!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "final_res = joined.groupby('index')['translation_reviewed'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "final_res['translation_reviewed'] = final_res.translation_reviewed.str.lower().str.strip(string_punct).str.replace(\".\", \"\")\n",
    "\n",
    "english_final_df = english_captions.merge(final_res, how=\"left\", left_on=\"index\", right_on=\"index\")\n",
    "english_final_df = english_final_df[[\"filename\", \"caption_lang\", \"clean_caption\", \"translation_reviewed\"]]\n",
    "english_final_df.columns = [\"filename\", \"caption_lang\", \"clean_caption\", \"translation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_caption_translations = pd.concat([english_final_df, hindi_final_df, other_final_df, empty_final_df], axis=\"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_caption_translations.to_csv(\"translations/ocr_round3_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_caption_translations[\"translation\"] = np.where(final_caption_translations.translation.isna(), final_caption_translations.clean_caption, final_caption_translations.translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_caption</th>\n",
       "      <th>caption_lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>551</td>\n",
       "      <td>geyK7EEbeKcKLjdR2EkkhLGJwDegAeHO4gkN</td>\n",
       "      <td>Rotate Your Phone For Better Experience @end @...</td>\n",
       "      <td>rotate your phone for better experience e ed e...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>762</td>\n",
       "      <td>Gr1lK55brlUrmpZ0YX44TjJ268OmrNC32vKZ</td>\n",
       "      <td>BAANYANISHAD34 GAANYANISHAD34 Sharma Billo Ran...</td>\n",
       "      <td>baanyanishad34 gaanyanishad34 sharma billo ran...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2592</td>\n",
       "      <td>eBXZeVVpBZTJbKDQjVEETgENxGX8VxCmQ7lW</td>\n",
       "      <td>777Shalinibulle EVERYDAY IS Geeta khonde Indir...</td>\n",
       "      <td>777shalinibulle everyday is geeta khonde indir...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2594</td>\n",
       "      <td>eBXZeVVpBZTJbKDQjVEETgER1ApR87TmwBN4</td>\n",
       "      <td>CreatorSakib 0786 Yogi ji Apne Hisab Se Theek ...</td>\n",
       "      <td>creatorsakib 0786 yogi ji apne hisab se theek ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2669</td>\n",
       "      <td>wPNGm99VPGTEv5P09kddTRZwjQ4kREIL8ygj</td>\n",
       "      <td>Please follow me HindutvaSheris HindutvaShets ...</td>\n",
       "      <td>please follow me hindutvasheris hindutvashets ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2907</td>\n",
       "      <td>rP3JlZZWPJTpPx64ve88FmDB3kNEo5hELP1r</td>\n",
       "      <td>CNN THIS MORNING DIGVIJAYKUMAR Wait For Yogi A...</td>\n",
       "      <td>cnn this morning digvijaykumar wait for yogi a...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                              filename  \\\n",
       "3     551  geyK7EEbeKcKLjdR2EkkhLGJwDegAeHO4gkN   \n",
       "5     762  Gr1lK55brlUrmpZ0YX44TjJ268OmrNC32vKZ   \n",
       "27   2592  eBXZeVVpBZTJbKDQjVEETgENxGX8VxCmQ7lW   \n",
       "28   2594  eBXZeVVpBZTJbKDQjVEETgER1ApR87TmwBN4   \n",
       "29   2669  wPNGm99VPGTEv5P09kddTRZwjQ4kREIL8ygj   \n",
       "33   2907  rP3JlZZWPJTpPx64ve88FmDB3kNEo5hELP1r   \n",
       "\n",
       "                                                 text  \\\n",
       "3   Rotate Your Phone For Better Experience @end @...   \n",
       "5   BAANYANISHAD34 GAANYANISHAD34 Sharma Billo Ran...   \n",
       "27  777Shalinibulle EVERYDAY IS Geeta khonde Indir...   \n",
       "28  CreatorSakib 0786 Yogi ji Apne Hisab Se Theek ...   \n",
       "29  Please follow me HindutvaSheris HindutvaShets ...   \n",
       "33  CNN THIS MORNING DIGVIJAYKUMAR Wait For Yogi A...   \n",
       "\n",
       "                                        clean_caption caption_lang  \n",
       "3   rotate your phone for better experience e ed e...           en  \n",
       "5   baanyanishad34 gaanyanishad34 sharma billo ran...           en  \n",
       "27  777shalinibulle everyday is geeta khonde indir...           en  \n",
       "28  creatorsakib 0786 yogi ji apne hisab se theek ...           en  \n",
       "29  please follow me hindutvasheris hindutvashets ...           en  \n",
       "33  cnn this morning digvijaykumar wait for yogi a...           en  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_captions.to_csv(\"translations/captions_too_long.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>caption_lang</th>\n",
       "      <th>clean_caption</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11QA4nnK1AHERwnV6AyyTblPJ7r1AVUN9eD6</td>\n",
       "      <td>en</td>\n",
       "      <td>ta jib crane pvtltd kanta jb</td>\n",
       "      <td>ta jib crane pvtltd kanta jb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3rmOYVVvrOUNAoByj9WWSZe0kQ2bvlf5NZje</td>\n",
       "      <td>en</td>\n",
       "      <td>jay naik talks business motivation socia jay n...</td>\n",
       "      <td>jay naik talks business motivation socia jay n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BgJDK880gDUv18KebL99TRJPjZ7mbPt4Y79x</td>\n",
       "      <td>en</td>\n",
       "      <td>sune kiyu dil ki baat 730</td>\n",
       "      <td>sune kiyu dil ki baat 730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XQAbDkkLQbiw0GnWg9ddIDN9GxRl3YclwmBg</td>\n",
       "      <td>en</td>\n",
       "      <td>meri ram ji se kah dena jay siyaram main ram s...</td>\n",
       "      <td>meri ram ji se kah dena jay siyaram main ram s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vP4j5223PjTGjVkr9pBBuELBoeEKAGfXY6Wl</td>\n",
       "      <td>en</td>\n",
       "      <td>wah daktar saheb wah</td>\n",
       "      <td>wah daktar saheb wah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vP4j5223PjTGjVkr9pBBuELp6b5Q5eIXBJ1E</td>\n",
       "      <td>en</td>\n",
       "      <td>wion india faces massive youth unemployment cr...</td>\n",
       "      <td>wion india faces massive youth unemployment cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wPNGm99VPGTEv5P09kddTRZbYyg9ercLjRBO</td>\n",
       "      <td>en</td>\n",
       "      <td>scopo us</td>\n",
       "      <td>scopo us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wPNGm99VPGTEv5P09kddTRZwLjP1x8SLjWmX</td>\n",
       "      <td>en</td>\n",
       "      <td>inews air india losses grow to 78000 cr image ...</td>\n",
       "      <td>inews air india losses grow to 78000 cr image ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2r7wN33WrwU5Xd0L7PbbIKZxp5wRK7SpBvBo</td>\n",
       "      <td>hi</td>\n",
       "      <td>rao sahab जय समाजवादी जय समाजवादी जय समाजवादी ...</td>\n",
       "      <td>rao sahab Jai Samajwadi Jai Samajwadi Jai Sama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2r7wN33WrwU5Xd0L7PbbIKZxpGOeG0cp5Krg</td>\n",
       "      <td>hi</td>\n",
       "      <td>कि सब लोटपोट हो जायें होजायें sy lstv lstv stv</td>\n",
       "      <td>So that everyone gets drunk, hojaaye sy lstv l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2r7wN33WrwU5Xd0L7PbbIKZr9RZQJ3IplNnJ</td>\n",
       "      <td>hi</td>\n",
       "      <td>12raju38 जय</td>\n",
       "      <td>12raju38 Jai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11QA4nnK1AHERwnV6AyyTblPJ07kgRTN9N26</td>\n",
       "      <td>hi</td>\n",
       "      <td>अमेरिका में बयान अमेठी में पलटवार ако india takna</td>\n",
       "      <td>Statement in America Counterattack in Amethi i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2r7wN33WrwU5Xd0L7PbbIKZxpljxBnfpEr99</td>\n",
       "      <td>hi</td>\n",
       "      <td>सेवा सुशासन दिल्ली कोसं pm आवासर दिल्ली के 30 ...</td>\n",
       "      <td>Service Good Governance Delhi Co. No. PM Awasa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3rmOYVVvrOUNAoByj9WWSZe0DG8YP6f5N5w2</td>\n",
       "      <td>hi</td>\n",
       "      <td>समाज</td>\n",
       "      <td>Society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4rAQ0LLGrQUKdw6yVXpphPl2GLJkg7uNjeEN</td>\n",
       "      <td>hi</td>\n",
       "      <td>akhileshiyans samsung amsuno amsung सौरम फोटौ ...</td>\n",
       "      <td>akhileshiyans samsung amsuno amsung sauram pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4rAQ0LLGrQUKdw6yVXpphPl2eDjLrlINKpJk</td>\n",
       "      <td>hi</td>\n",
       "      <td>va pm ऐसा किया m ऐसा किया in god we trust</td>\n",
       "      <td>va pm did it m did it in god we trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5rwR5EEnrRUd0X6N2Z11T27NklwNYmcpmBwx</td>\n",
       "      <td>hi</td>\n",
       "      <td>अगर बुल्डोज़र समाजवादियों पे चले है तो भाजपा व...</td>\n",
       "      <td>If the bulldozers attack the socialists, then ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6P0OR443POT74XKY1x22TWkZNmPmLySjprbZ</td>\n",
       "      <td>hi</td>\n",
       "      <td>एक्सप्रेस के अंदर का हाल बारिश में देखिये वन्द...</td>\n",
       "      <td>Vande Bharat, see the condition inside the exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9rpw0QQErwU5RVAmKGQQIkv6W0mYn4SVbxEg</td>\n",
       "      <td>hi</td>\n",
       "      <td>narur rss वालो की मानसिकता क्या बोलती है देखा ...</td>\n",
       "      <td>narur What does the mentality of RSS people sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BgJDK880gDUv18KebL99TRJgolvBNmF4KJy8</td>\n",
       "      <td>hi</td>\n",
       "      <td>हम सब सनातनी wait 1md please 700 1md please 70...</td>\n",
       "      <td>We all Sanatani wait 1md please 700 1md please...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Drldx22ZrdUpXW2ENbPPFAKGbnVO69HwdmjL</td>\n",
       "      <td>hi</td>\n",
       "      <td>आओ कहीं ओर चलके मुहोब्त करें जहाँ मिलजाए लोगों...</td>\n",
       "      <td>Let's go somewhere else and love each other, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Drldx22ZrdUpXW2ENbPPFAKGxxgrlQSwr0xL</td>\n",
       "      <td>hi</td>\n",
       "      <td>vita follow comment rockstarnk alok rockstar n...</td>\n",
       "      <td>vita follow comment rockstarnk alok rockstar n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Q3E26DDK32H4o28v3AZZSXpBVRWOWxHZp7w2</td>\n",
       "      <td>hi</td>\n",
       "      <td>दो लाइने है मां के लिए बड़ी बेबसी में सूरज से ...</td>\n",
       "      <td>There are two lines for mother: In great helpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RV4L655WVLI9EjP0r2ppHd2Ze5kkmAIwLN2K</td>\n",
       "      <td>hi</td>\n",
       "      <td>जय श्री राम qipsskyakash03</td>\n",
       "      <td>Jai Shri Ram qipsskyakash03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>VN7YD553NYHmJ1Qn3xooseZgwkQprVhkLA7k</td>\n",
       "      <td>hi</td>\n",
       "      <td>ek khawab कम्बखत वो भी मेरे संग रह गई छोटी छोट...</td>\n",
       "      <td>ek khawab Damned she also stayed with me Even ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XQAbDkkLQbiw0GnWg9ddIDN9AvvvO1IlwmPN</td>\n",
       "      <td>hi</td>\n",
       "      <td>चाहते है उड़ते हुए परिंदो की यही सच्चाई है आजक...</td>\n",
       "      <td>This is the truth of flying birds, they want t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Y7wdD55E7dtRp5PD0OeeClWeygdNw3svRkJv</td>\n",
       "      <td>hi</td>\n",
       "      <td>laugh political कौन ज़ालिम है यहां जुल्म हुआ ह...</td>\n",
       "      <td>laugh political Who is the cruel one, the inju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Zm0ZD559mZCjx85k06XXFXyV8YV1omHdww9b</td>\n",
       "      <td>hi</td>\n",
       "      <td>2024 में नजर india नहीं आएंगे मोदी पर खूब बोले...</td>\n",
       "      <td>India will not be seen in 2024 Tejashwi spoke ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>eBXZeVVpBZTJbKDQjVEETgENxGK5djfmQ7l8</td>\n",
       "      <td>hi</td>\n",
       "      <td>9 साल मे इतना विकास हुआ की छुपाना पड़ रहा है f...</td>\n",
       "      <td>There has been so much development in 9 years ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>jPreKYYBPeTwlbpKdYkkIJBb2vV8pmHp116l</td>\n",
       "      <td>hi</td>\n",
       "      <td>अलावा कोई मुद्दा नहीं मोदी योगी को गाली देने क...</td>\n",
       "      <td>There is no issue other than Modi abusing Yogi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>jPreKYYBPeTwlbpKdYkkIJBkArAlg1cpejwP</td>\n",
       "      <td>hi</td>\n",
       "      <td>like foto जब कुत्ता सूअर बन्दर भैंस लोमड़ी गधे...</td>\n",
       "      <td>like photo When dog, pig, monkey, buffalo, fox...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>oPvXdwwyPXT1rP6o0DjjTwZ9Lve12jtljBWW</td>\n",
       "      <td>hi</td>\n",
       "      <td>mp birla cement perfect plus escorpio escorpio...</td>\n",
       "      <td>mp birla cement perfect plus escorpio escorpio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>xPYr5BBLPrTOx6PADjeeuXd0wb9QyRf3Q4NY</td>\n",
       "      <td>hi</td>\n",
       "      <td>mai sakshi ke pariwar se mil ke aayi आम दम 202...</td>\n",
       "      <td>I met Sakshi's family and came to know Aam Dum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>xPYr5BBLPrTOx6PADjeeuXdKrJdOWeU3Q4NB</td>\n",
       "      <td>hi</td>\n",
       "      <td>भ्रष्ट भूपेश सरकार में फिर एक बार ध्वस्त हुई श...</td>\n",
       "      <td>Under the corrupt Bhupesh government, the educ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>xPYr5BBLPrTOx6PADjeeuXdKrXLdebF3pLNE</td>\n",
       "      <td>hi</td>\n",
       "      <td>81 हजार करोड़ का फायदा</td>\n",
       "      <td>profit of 81 thousand crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>yPQ3oWWEP3Tekd2ZX399up39AO0ByGIYO2NR</td>\n",
       "      <td>hi</td>\n",
       "      <td>बुरी</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>yPQ3oWWEP3Tekd2ZX399up39DevbOlTYxldP</td>\n",
       "      <td>hi</td>\n",
       "      <td>बागाड़ बाम बाम लाहरी बामालाहरी</td>\n",
       "      <td>Bagaaad baam baam lahari bamalahari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32eb982c_1687584296231</td>\n",
       "      <td>empty</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>E5Kygoop5yCo58QGE9LLTw3B0kdPL9UxoLJ7</td>\n",
       "      <td>empty</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VN7YD553NYHmJ1Qn3xooseZgmbwQmdTkgXQQ</td>\n",
       "      <td>empty</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XQAbDkkLQbiw0GnWg9ddIDN9A56Y17hlDj7p</td>\n",
       "      <td>empty</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>XQAbDkkLQbiw0GnWg9ddIDNnZj90Q9hlp9g2</td>\n",
       "      <td>empty</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Y7wdD55E7dtRp5PD0OeeClWwRrrNP0HvYey3</td>\n",
       "      <td>empty</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Zm0ZD559mZCjx85k06XXFXyV8Ygb3LtdJXVk</td>\n",
       "      <td>empty</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Zm0ZD559mZCjx85k06XXFXybw5mvQ9Cdx6mj</td>\n",
       "      <td>empty</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>doeN733ZoNtXepVOb3LLfVN2K3X3G9CQwmBW</td>\n",
       "      <td>empty</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>pPGjB00lPjTdywNrOpZZTpyPxmpeeyUd26xn</td>\n",
       "      <td>empty</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>rP3JlZZWPJTpPx64ve88FmDB3NDbbeTENXGm</td>\n",
       "      <td>empty</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>xPYr5BBLPrTOx6PADjeeuXdKyGVbowC3pL2o</td>\n",
       "      <td>empty</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                filename caption_lang  \\\n",
       "0   11QA4nnK1AHERwnV6AyyTblPJ7r1AVUN9eD6           en   \n",
       "1   3rmOYVVvrOUNAoByj9WWSZe0kQ2bvlf5NZje           en   \n",
       "2   BgJDK880gDUv18KebL99TRJPjZ7mbPt4Y79x           en   \n",
       "3   XQAbDkkLQbiw0GnWg9ddIDN9GxRl3YclwmBg           en   \n",
       "4   vP4j5223PjTGjVkr9pBBuELBoeEKAGfXY6Wl           en   \n",
       "5   vP4j5223PjTGjVkr9pBBuELp6b5Q5eIXBJ1E           en   \n",
       "6   wPNGm99VPGTEv5P09kddTRZbYyg9ercLjRBO           en   \n",
       "7   wPNGm99VPGTEv5P09kddTRZwLjP1x8SLjWmX           en   \n",
       "0   2r7wN33WrwU5Xd0L7PbbIKZxp5wRK7SpBvBo           hi   \n",
       "1   2r7wN33WrwU5Xd0L7PbbIKZxpGOeG0cp5Krg           hi   \n",
       "2   2r7wN33WrwU5Xd0L7PbbIKZr9RZQJ3IplNnJ           hi   \n",
       "3   11QA4nnK1AHERwnV6AyyTblPJ07kgRTN9N26           hi   \n",
       "4   2r7wN33WrwU5Xd0L7PbbIKZxpljxBnfpEr99           hi   \n",
       "5   3rmOYVVvrOUNAoByj9WWSZe0DG8YP6f5N5w2           hi   \n",
       "6   4rAQ0LLGrQUKdw6yVXpphPl2GLJkg7uNjeEN           hi   \n",
       "7   4rAQ0LLGrQUKdw6yVXpphPl2eDjLrlINKpJk           hi   \n",
       "8   5rwR5EEnrRUd0X6N2Z11T27NklwNYmcpmBwx           hi   \n",
       "9   6P0OR443POT74XKY1x22TWkZNmPmLySjprbZ           hi   \n",
       "10  9rpw0QQErwU5RVAmKGQQIkv6W0mYn4SVbxEg           hi   \n",
       "11  BgJDK880gDUv18KebL99TRJgolvBNmF4KJy8           hi   \n",
       "12  Drldx22ZrdUpXW2ENbPPFAKGbnVO69HwdmjL           hi   \n",
       "13  Drldx22ZrdUpXW2ENbPPFAKGxxgrlQSwr0xL           hi   \n",
       "14  Q3E26DDK32H4o28v3AZZSXpBVRWOWxHZp7w2           hi   \n",
       "15  RV4L655WVLI9EjP0r2ppHd2Ze5kkmAIwLN2K           hi   \n",
       "16  VN7YD553NYHmJ1Qn3xooseZgwkQprVhkLA7k           hi   \n",
       "17  XQAbDkkLQbiw0GnWg9ddIDN9AvvvO1IlwmPN           hi   \n",
       "18  Y7wdD55E7dtRp5PD0OeeClWeygdNw3svRkJv           hi   \n",
       "19  Zm0ZD559mZCjx85k06XXFXyV8YV1omHdww9b           hi   \n",
       "20  eBXZeVVpBZTJbKDQjVEETgENxGK5djfmQ7l8           hi   \n",
       "21  jPreKYYBPeTwlbpKdYkkIJBb2vV8pmHp116l           hi   \n",
       "22  jPreKYYBPeTwlbpKdYkkIJBkArAlg1cpejwP           hi   \n",
       "23  oPvXdwwyPXT1rP6o0DjjTwZ9Lve12jtljBWW           hi   \n",
       "24  xPYr5BBLPrTOx6PADjeeuXd0wb9QyRf3Q4NY           hi   \n",
       "25  xPYr5BBLPrTOx6PADjeeuXdKrJdOWeU3Q4NB           hi   \n",
       "26  xPYr5BBLPrTOx6PADjeeuXdKrXLdebF3pLNE           hi   \n",
       "27  yPQ3oWWEP3Tekd2ZX399up39AO0ByGIYO2NR           hi   \n",
       "28  yPQ3oWWEP3Tekd2ZX399up39DevbOlTYxldP           hi   \n",
       "6                 32eb982c_1687584296231        empty   \n",
       "18  E5Kygoop5yCo58QGE9LLTw3B0kdPL9UxoLJ7        empty   \n",
       "21  VN7YD553NYHmJ1Qn3xooseZgmbwQmdTkgXQQ        empty   \n",
       "23  XQAbDkkLQbiw0GnWg9ddIDN9A56Y17hlDj7p        empty   \n",
       "26  XQAbDkkLQbiw0GnWg9ddIDNnZj90Q9hlp9g2        empty   \n",
       "28  Y7wdD55E7dtRp5PD0OeeClWwRrrNP0HvYey3        empty   \n",
       "30  Zm0ZD559mZCjx85k06XXFXyV8Ygb3LtdJXVk        empty   \n",
       "31  Zm0ZD559mZCjx85k06XXFXybw5mvQ9Cdx6mj        empty   \n",
       "32  doeN733ZoNtXepVOb3LLfVN2K3X3G9CQwmBW        empty   \n",
       "37  pPGjB00lPjTdywNrOpZZTpyPxmpeeyUd26xn        empty   \n",
       "38  rP3JlZZWPJTpPx64ve88FmDB3NDbbeTENXGm        empty   \n",
       "46  xPYr5BBLPrTOx6PADjeeuXdKyGVbowC3pL2o        empty   \n",
       "\n",
       "                                        clean_caption  \\\n",
       "0                        ta jib crane pvtltd kanta jb   \n",
       "1   jay naik talks business motivation socia jay n...   \n",
       "2                           sune kiyu dil ki baat 730   \n",
       "3   meri ram ji se kah dena jay siyaram main ram s...   \n",
       "4                                wah daktar saheb wah   \n",
       "5   wion india faces massive youth unemployment cr...   \n",
       "6                                            scopo us   \n",
       "7   inews air india losses grow to 78000 cr image ...   \n",
       "0   rao sahab जय समाजवादी जय समाजवादी जय समाजवादी ...   \n",
       "1      कि सब लोटपोट हो जायें होजायें sy lstv lstv stv   \n",
       "2                                         12raju38 जय   \n",
       "3   अमेरिका में बयान अमेठी में पलटवार ако india takna   \n",
       "4   सेवा सुशासन दिल्ली कोसं pm आवासर दिल्ली के 30 ...   \n",
       "5                                                समाज   \n",
       "6   akhileshiyans samsung amsuno amsung सौरम फोटौ ...   \n",
       "7           va pm ऐसा किया m ऐसा किया in god we trust   \n",
       "8   अगर बुल्डोज़र समाजवादियों पे चले है तो भाजपा व...   \n",
       "9   एक्सप्रेस के अंदर का हाल बारिश में देखिये वन्द...   \n",
       "10  narur rss वालो की मानसिकता क्या बोलती है देखा ...   \n",
       "11  हम सब सनातनी wait 1md please 700 1md please 70...   \n",
       "12  आओ कहीं ओर चलके मुहोब्त करें जहाँ मिलजाए लोगों...   \n",
       "13  vita follow comment rockstarnk alok rockstar n...   \n",
       "14  दो लाइने है मां के लिए बड़ी बेबसी में सूरज से ...   \n",
       "15                         जय श्री राम qipsskyakash03   \n",
       "16  ek khawab कम्बखत वो भी मेरे संग रह गई छोटी छोट...   \n",
       "17  चाहते है उड़ते हुए परिंदो की यही सच्चाई है आजक...   \n",
       "18  laugh political कौन ज़ालिम है यहां जुल्म हुआ ह...   \n",
       "19  2024 में नजर india नहीं आएंगे मोदी पर खूब बोले...   \n",
       "20  9 साल मे इतना विकास हुआ की छुपाना पड़ रहा है f...   \n",
       "21  अलावा कोई मुद्दा नहीं मोदी योगी को गाली देने क...   \n",
       "22  like foto जब कुत्ता सूअर बन्दर भैंस लोमड़ी गधे...   \n",
       "23  mp birla cement perfect plus escorpio escorpio...   \n",
       "24  mai sakshi ke pariwar se mil ke aayi आम दम 202...   \n",
       "25  भ्रष्ट भूपेश सरकार में फिर एक बार ध्वस्त हुई श...   \n",
       "26                             81 हजार करोड़ का फायदा   \n",
       "27                                               बुरी   \n",
       "28                     बागाड़ बाम बाम लाहरी बामालाहरी   \n",
       "6                                                       \n",
       "18                                                      \n",
       "21                                                      \n",
       "23                                                      \n",
       "26                                                      \n",
       "28                                                      \n",
       "30                                                      \n",
       "31                                                      \n",
       "32                                                      \n",
       "37                                                      \n",
       "38                                                      \n",
       "46                                                      \n",
       "\n",
       "                                          translation  \n",
       "0                        ta jib crane pvtltd kanta jb  \n",
       "1   jay naik talks business motivation socia jay n...  \n",
       "2                           sune kiyu dil ki baat 730  \n",
       "3   meri ram ji se kah dena jay siyaram main ram s...  \n",
       "4                                wah daktar saheb wah  \n",
       "5   wion india faces massive youth unemployment cr...  \n",
       "6                                            scopo us  \n",
       "7   inews air india losses grow to 78000 cr image ...  \n",
       "0   rao sahab Jai Samajwadi Jai Samajwadi Jai Sama...  \n",
       "1   So that everyone gets drunk, hojaaye sy lstv l...  \n",
       "2                                        12raju38 Jai  \n",
       "3   Statement in America Counterattack in Amethi i...  \n",
       "4   Service Good Governance Delhi Co. No. PM Awasa...  \n",
       "5                                             Society  \n",
       "6   akhileshiyans samsung amsuno amsung sauram pho...  \n",
       "7               va pm did it m did it in god we trust  \n",
       "8   If the bulldozers attack the socialists, then ...  \n",
       "9   Vande Bharat, see the condition inside the exp...  \n",
       "10  narur What does the mentality of RSS people sa...  \n",
       "11  We all Sanatani wait 1md please 700 1md please...  \n",
       "12  Let's go somewhere else and love each other, w...  \n",
       "13  vita follow comment rockstarnk alok rockstar n...  \n",
       "14  There are two lines for mother: In great helpl...  \n",
       "15                        Jai Shri Ram qipsskyakash03  \n",
       "16  ek khawab Damned she also stayed with me Even ...  \n",
       "17  This is the truth of flying birds, they want t...  \n",
       "18  laugh political Who is the cruel one, the inju...  \n",
       "19  India will not be seen in 2024 Tejashwi spoke ...  \n",
       "20  There has been so much development in 9 years ...  \n",
       "21  There is no issue other than Modi abusing Yogi...  \n",
       "22  like photo When dog, pig, monkey, buffalo, fox...  \n",
       "23  mp birla cement perfect plus escorpio escorpio...  \n",
       "24  I met Sakshi's family and came to know Aam Dum...  \n",
       "25  Under the corrupt Bhupesh government, the educ...  \n",
       "26                       profit of 81 thousand crores  \n",
       "27                                                bad  \n",
       "28                Bagaaad baam baam lahari bamalahari  \n",
       "6                                                      \n",
       "18                                                     \n",
       "21                                                     \n",
       "23                                                     \n",
       "26                                                     \n",
       "28                                                     \n",
       "30                                                     \n",
       "31                                                     \n",
       "32                                                     \n",
       "37                                                     \n",
       "38                                                     \n",
       "46                                                     "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_caption_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hi       1483\n",
       "en        983\n",
       "empty     593\n",
       "other     102\n",
       "gj         11\n",
       "Name: caption_lang, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.caption_lang.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_caption</th>\n",
       "      <th>caption_lang</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ArXogppwroUVpeDRgbGGTJkv8BWjWXFNVdp7</td>\n",
       "      <td>ANI गुरु चेला योगी आदित्यनाथ जी मुख्यमंत्री यू...</td>\n",
       "      <td>ani गुरु चेला योगी आदित्यनाथ जी मुख्यमंत्री यू...</td>\n",
       "      <td>hi</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ArXogppwroUVpeDRgbGGTJkv8PjG2EUNy3ne</td>\n",
       "      <td>Akhilesh |srkar</td>\n",
       "      <td>akhilesh srkar</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ArXogppwroUVpeDRgbGGTJkv8PnJWBhNKRQ9</td>\n",
       "      <td>EWS</td>\n",
       "      <td>ews</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BgJDK880gDUv18KebL99TRJGmXBgx2s4KJy0</td>\n",
       "      <td>Jai shree ram Jai shree ram, Jai shree rame Ja...</td>\n",
       "      <td>jai shree ram jai shree ram jai shree rame jai...</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>BgJDK880gDUv18KebL99TRJGmpNodLS4KJy8</td>\n",
       "      <td>I believe that Investigating in a Teleprompter...</td>\n",
       "      <td>i believe that investigating in a teleprompter...</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>3167</td>\n",
       "      <td>pPGjB00lPjTdywNrOpZZTpyBKDKYp1ud3QXx</td>\n",
       "      <td>- सूर्य प्रताप सिंह, पूर्व IAS BOLTA HINDUSTAN...</td>\n",
       "      <td>सूर्य प्रताप सिंह पूर्व ias bolta hindustan कर...</td>\n",
       "      <td>hi</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>3168</td>\n",
       "      <td>pPGjB00lPjTdywNrOpZZTpyP78AVv8Id3Q83</td>\n",
       "      <td>Altaf Raza Vlogs Last Tak dekho Oy Wait for en...</td>\n",
       "      <td>altaf raza vlogs last tak dekho oy wait for en...</td>\n",
       "      <td>hi</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>3169</td>\n",
       "      <td>rP3JlZZWPJTpPx64ve88FmDY4Px194UENXNB</td>\n",
       "      <td>(@IndiaTakoo 00 @IndiaTakoo @IndiaTakool शाह स...</td>\n",
       "      <td>00 शाह से मिले मांझी एनडीए में होंगे शामिल pin...</td>\n",
       "      <td>hi</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>3170</td>\n",
       "      <td>vP4j5223PjTGjVkr9pBBuEL4DZWApkHXO1rL</td>\n",
       "      <td>Chand</td>\n",
       "      <td>chand</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>3171</td>\n",
       "      <td>vP4j5223PjTGjVkr9pBBuELAjmJYE2HX59xO</td>\n",
       "      <td>पोल खोली? मोदी ने किसकी सन, 66 पार ला CIK पोल ...</td>\n",
       "      <td>पोल खोली मोदी ने किसकी सन 66 पार ला cik पोल खो...</td>\n",
       "      <td>hi</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3172 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                              filename  \\\n",
       "0         0  ArXogppwroUVpeDRgbGGTJkv8BWjWXFNVdp7   \n",
       "1         1  ArXogppwroUVpeDRgbGGTJkv8PjG2EUNy3ne   \n",
       "2         2  ArXogppwroUVpeDRgbGGTJkv8PnJWBhNKRQ9   \n",
       "3         3  BgJDK880gDUv18KebL99TRJGmXBgx2s4KJy0   \n",
       "4         4  BgJDK880gDUv18KebL99TRJGmpNodLS4KJy8   \n",
       "...     ...                                   ...   \n",
       "3167   3167  pPGjB00lPjTdywNrOpZZTpyBKDKYp1ud3QXx   \n",
       "3168   3168  pPGjB00lPjTdywNrOpZZTpyP78AVv8Id3Q83   \n",
       "3169   3169  rP3JlZZWPJTpPx64ve88FmDY4Px194UENXNB   \n",
       "3170   3170  vP4j5223PjTGjVkr9pBBuEL4DZWApkHXO1rL   \n",
       "3171   3171  vP4j5223PjTGjVkr9pBBuELAjmJYE2HX59xO   \n",
       "\n",
       "                                                   text  \\\n",
       "0     ANI गुरु चेला योगी आदित्यनाथ जी मुख्यमंत्री यू...   \n",
       "1                                       Akhilesh |srkar   \n",
       "2                                                   EWS   \n",
       "3     Jai shree ram Jai shree ram, Jai shree rame Ja...   \n",
       "4     I believe that Investigating in a Teleprompter...   \n",
       "...                                                 ...   \n",
       "3167  - सूर्य प्रताप सिंह, पूर्व IAS BOLTA HINDUSTAN...   \n",
       "3168  Altaf Raza Vlogs Last Tak dekho Oy Wait for en...   \n",
       "3169  (@IndiaTakoo 00 @IndiaTakoo @IndiaTakool शाह स...   \n",
       "3170                                              Chand   \n",
       "3171  पोल खोली? मोदी ने किसकी सन, 66 पार ला CIK पोल ...   \n",
       "\n",
       "                                          clean_caption caption_lang  \\\n",
       "0     ani गुरु चेला योगी आदित्यनाथ जी मुख्यमंत्री यू...           hi   \n",
       "1                                        akhilesh srkar           en   \n",
       "2                                                   ews           en   \n",
       "3     jai shree ram jai shree ram jai shree rame jai...           en   \n",
       "4     i believe that investigating in a teleprompter...           en   \n",
       "...                                                 ...          ...   \n",
       "3167  सूर्य प्रताप सिंह पूर्व ias bolta hindustan कर...           hi   \n",
       "3168  altaf raza vlogs last tak dekho oy wait for en...           hi   \n",
       "3169  00 शाह से मिले मांझी एनडीए में होंगे शामिल pin...           hi   \n",
       "3170                                              chand           en   \n",
       "3171  पोल खोली मोदी ने किसकी सन 66 पार ला cik पोल खो...           hi   \n",
       "\n",
       "     translation  \n",
       "0                 \n",
       "1                 \n",
       "2                 \n",
       "3                 \n",
       "4                 \n",
       "...          ...  \n",
       "3167              \n",
       "3168              \n",
       "3169              \n",
       "3170              \n",
       "3171              \n",
       "\n",
       "[3172 rows x 6 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subscribe of a on on on on on on on on on multiplayer multiplayer report report report fb fb hash it first podcast music ar smile prakash prakash prakash also also also also also also also also also available available available available available available available available available smile light vita smit aash kash yt insightful coverage global issues'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_caption_translations.iloc[26].translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the issue with filenames not included with translations\n",
    "final_ocrdf = pd.read_csv(\"translations/ocr_final.csv\")\n",
    "final_ocrdf.merge(combined, how=\"left\", left_on=\"clean_caption\", right_on=\"clean_caption\").to_csv(\"translations/test_ocr_fix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "testocr = pd.read_csv(\"translations/test_ocr_fix.csv\").dropna(subset=['clean_caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'caption_lang', 'clean_caption', 'translation'], dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ocrdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'caption_lang', 'clean_caption', 'translation'], dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "testocr = testocr[[\"filename\", 'caption_lang_x', 'clean_caption', 'translation']]\n",
    "testocr.columns = [\"filename\", 'caption_lang', 'clean_caption', 'translation']\n",
    "final_fixdf = pd.concat([testocr, empty_final_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fixdf.to_csv(\"translations/ocr_final.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
